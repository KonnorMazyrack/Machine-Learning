# -*- coding: utf-8 -*-
"""ML_Lab10Ex2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YCqdHXLSPfrt92s_U9QdsGjS_opvxDdJ
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from matplotlib import pyplot as plt


names = ['area', 'perimeter', 'compactness', 'lKer', 'wKer', 'asymKer', 'lKerGroove']
lbl = ['Kama', 'Rosa', 'Canadian']
classes_dict = dict(zip([x for x in range(len(lbl))], lbl))
data = []
with open('sample_data/seeds_dataset.txt', 'r') as f:
  for line in f:
    values = line.strip().split()
    data.append([float(v) for v in values])

data = np.array(data)
print(f'Data: {data}')

X = data[:, 0:7]
y = data[:, 7]
print(X)
print(y)

# Standardize features (recommended for neural networks)
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Define MLPClassifier to match Keras model
model = MLPClassifier(
    hidden_layer_sizes=(32, 16, 4),  # Three hidden layers: 1000, 500, 300 units
    activation='relu',                    # ReLU activation
    solver='adam',                       # Adam optimizer
    max_iter=500,                        # Equivalent to EPOCHS
    batch_size=16,                       # Equivalent to BATCH_SIZE
    alpha=0.0001,                        # L2 regularization to approximate dropout
    random_state=None,                   # No random seed to match Keras
    verbose=True,                        # Print training progress
    early_stopping=False                 # No validation during training to match Keras
)

# Train the model
model.fit(X_train, y_train)

# Predict on test set
pred = model.predict(X_test)  # Direct prediction of class indices
as1 = accuracy_score(y_test, pred)


model2 = MLPClassifier(
    hidden_layer_sizes=(100, 100),  # Three hidden layers: 1000, 500, 300 units
    activation='relu',                    # ReLU activation
    solver='adam',                       # Adam optimizer
    max_iter=10,                        # Equivalent to EPOCHS
    batch_size=16,                       # Equivalent to BATCH_SIZE
    alpha=0.0001,                        # L2 regularization to approximate dropout
    random_state=None,                   # No random seed to match Keras
    verbose=True,                        # Print training progress
    early_stopping=False                 # No validation during training to match Keras
)

# Train the model
model2.fit(X_train, y_train)

# Predict on test set
pred2 = model2.predict(X_test)  # Direct prediction of class indices
as2 = accuracy_score(y_test, pred2)

model3 = MLPClassifier(
    hidden_layer_sizes=(16, 16),  # Three hidden layers: 1000, 500, 300 units
    activation='relu',                    # ReLU activation
    solver='adam',                       # Adam optimizer
    max_iter=50,                        # Equivalent to EPOCHS
    batch_size=16,                       # Equivalent to BATCH_SIZE
    alpha=0.0001,                        # L2 regularization to approximate dropout
    random_state=None,                   # No random seed to match Keras
    verbose=True,                        # Print training progress
    early_stopping=False                 # No validation during training to match Keras
)

# Train the model
model3.fit(X_train, y_train)

# Predict on test set
pred3 = model3.predict(X_test)  # Direct prediction of class indices
as3 = accuracy_score(y_test, pred3)

# Print accuracy score
print(f'(model1) Accuracy score: {as1}')
print(f'(model2) Accuracy score: {as2}')
print(f'(model3) Accuracy score: {as3}')